{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COS 802 Final Project <br> Student Number: u11028182 <br> Name:  Erika Scholtz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and filter dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/COS802/AylienCovid19.csv') # --> Change to location of extracted AylienCovid19 csv file\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many news articles are available for each Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of relevant economic impact keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['business','businesses','economy','economic','GDP','gross domestic product','jobs','unemployment','industry',\n",
    "             'trade', 'shortage', 'panic buying','stocks','stock','market','investment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter dataframe to include only news article that contain one or more of the keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = df[df['body'].str.contains('|'.join(keywords),case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for specific countries and create text documents for each country based on a subset of the news articles. Countries were selected for the created number of articles availabe. South Africa was added as an additional country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_US = df_f[df_f['location']=='US'].body.sample(10000,random_state = 101)  # --> 232850 entries in full set\n",
    "text_GB = df_f[df_f['location']=='GB'].body.sample(10000,random_state = 101)  # --> 102161 entries in full set\n",
    "text_IN = df_f[df_f['location']=='IN'].body.sample(10000,random_state = 101)  # --> 80247 entries in full set\n",
    "text_CA = df_f[df_f['location']=='CA'].body.sample(10000,random_state = 101)  # --> 19373 entries in full set\n",
    "text_AU = df_f[df_f['location']=='AU'].body.sample(10000,random_state = 101)  # --> 19954 entries in full set\n",
    "text_ZA = df_f[df_f['location']=='ZA'].body  # --> 1834 entries in full set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load subset for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_f_c[['id','body','location']].sample(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data preprocessing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define list of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm',disable=['parser','ner'])\n",
    "nlp.Defaults.stop_words |= {'say','go','know','think'}\n",
    "stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data preporcessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Remove stopwords, run through language model, and lemmatize ---------\n",
    "\n",
    "def clean_text(text_data, allowed_types=['NOUN','ADJ','VERB','ADV']):\n",
    "    \n",
    "    lemma_text = []\n",
    "    \n",
    "    for text in text_data:\n",
    "        doc = nlp(text)\n",
    "        new = []\n",
    "        \n",
    "        for token in doc:\n",
    "            if (token.pos_ in allowed_types) and (token.text.lower() not in stopwords):\n",
    "                lem = token.lemma_\n",
    "                \n",
    "                if lem not in stopwords:\n",
    "                    new.append(lem)\n",
    "                               \n",
    "        new_text = \" \".join(new)\n",
    "        lemma_text.append(new_text)\n",
    "\n",
    "# ---------- Further Preprocess data ----------\n",
    "\n",
    "    words = []\n",
    "    \n",
    "    for text in lemma_text:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        words.append(new)    \n",
    "        \n",
    "    return lemma_text, words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions for bigram and trigram models and tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_bigrams(text_data,min_count=5,threshold=100):\n",
    "    \n",
    "    bigram_phrases = gensim.models.Phrases(text_data,min_count=min_count,threshold=threshold)\n",
    "    trigram_phrases = gensim.models.Phrases(bigram_phrases[text_data],threshold=threshold)\n",
    "\n",
    "    bigram = gensim.models.phrases.Phraser(bigram_phrases)\n",
    "    trigram = gensim.models.phrases.Phraser(trigram_phrases)\n",
    "\n",
    "    def to_bigrams(texts):\n",
    "        return([bigram[doc] for doc in texts])\n",
    "\n",
    "    def to_trigrams(texts):\n",
    "        return ([trigram[bigram[doc]] for doc in texts])\n",
    "\n",
    "    text_bigrams = to_bigrams(text_data)\n",
    "    text_bi_trigrams = to_trigrams(text_bigrams)\n",
    "\n",
    "    return text_bi_trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create id2word and corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_prep(text_data):\n",
    "    id2word = corpora.Dictionary(text_data)\n",
    "\n",
    "    corpus = []\n",
    "    \n",
    "    for text in text_data:\n",
    "        new = id2word.doc2bow(text)\n",
    "        corpus.append(new)\n",
    "    \n",
    "    return id2word, corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(corpus, id2word):\n",
    "    tfidf = TfidfModel(corpus=corpus, id2word=id2word)\n",
    "\n",
    "    threshold = 0.03\n",
    "    words = []\n",
    "    words_not_in_tfidf = []\n",
    "\n",
    "    for i in range(0,len(corpus)):\n",
    "        bow = corpus[i]\n",
    "        low_value_words = []\n",
    "        \n",
    "        tfidf_ids = [id for id, value in tfidf[bow]]\n",
    "        \n",
    "        bow_ids = [id for id, value in bow]\n",
    "        \n",
    "        low_value_words = [id for id, value in tfidf[bow] if value < threshold]\n",
    "        \n",
    "        drops = low_value_words+words_not_in_tfidf\n",
    "        \n",
    "        for item in drops:\n",
    "            words.append(id2word[item])\n",
    "            \n",
    "        words_not_in_tfidf = [id for id in bow_ids if id not in tfidf_ids]\n",
    "\n",
    "        new_bow = [b for b in bow if b[0] not in low_value_words and b[0] not in words_not_in_tfidf]\n",
    "        \n",
    "        corpus[i] =new_bow\n",
    "        \n",
    "    return corpus, id2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_k(corpus,id2word,texts,save_name):\n",
    "    \n",
    "    coherence = []\n",
    "\n",
    "    for k in range(10,37,2):\n",
    "        print('Test for k value of: '+str(k))\n",
    "        \n",
    "        Lda_model = gensim.models.ldamulticore.LdaModel(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=k,\n",
    "                                                        random_state=100,\n",
    "                                                        update_every=1,\n",
    "                                                        chunksize=500,\n",
    "                                                        passes=20,\n",
    "                                                        alpha='auto')\n",
    "\n",
    "        coher_model = gensim.models.coherencemodel.CoherenceModel(model=Lda_model,\n",
    "                                                         texts=texts,\n",
    "                                                         corpus=corpus,\n",
    "                                                         dictionary=id2word,\n",
    "                                                         coherence='c_v')\n",
    "        \n",
    "        coherence.append((k,coher_model.get_coherence()))\n",
    "\n",
    "    k = []\n",
    "    c = []\n",
    "    for i in coherence:\n",
    "        k.append(i[0])\n",
    "        c.append(i[1]) \n",
    "    \n",
    "    pd.DataFrame(list(zip(k, c))).to_csv(save_name + \".csv\",index=False)\n",
    "    \n",
    "    return k, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build topic model for the United States (US)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### US: Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erika.scholtz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "# ---------- Clean text ----------\n",
    "lemma_text_US, text_words_US = clean_text(text_US)\n",
    "\n",
    "# print('Lemmatized: ',lemma_text_US[0][0:100],'\\n')\n",
    "# print('Tokenized: ',text_words_US[0][0:20])\n",
    "\n",
    "# ---------- Create bigrams and trigrams ----------\n",
    "text_words_US_2 =  tri_bigrams(text_words_US,min_count=5,threshold=100)\n",
    "id2word_US, corpus_US = corpus_prep(text_words_US_2)\n",
    "\n",
    "# ---------- TF-IDF and create corpus and dictionary ----------\n",
    "corpus_US, id2words_US = tf_idf(corpus_US, id2word_US)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### US: Find optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_US, c_US = opt_k(corpus_US,id2word_US,text_words_US_2,\"US_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(5,2.5))\n",
    "plt.tight_layout\n",
    "\n",
    "plt.plot(k_US,c_US)\n",
    "\n",
    "plt.title('Number of topics vs. coherence for US')\n",
    "plt.xlabel('Number of topics')\n",
    "plt.ylabel('Coherence')\n",
    "plt.savefig('US_Topics_K.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### US: Final LDA Model and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_US = gensim.models.ldamulticore.LdaModel(corpus=corpus_US,\n",
    "                                                   id2word=id2word_US,\n",
    "                                                   num_topics=14,\n",
    "                                                   random_state=100,\n",
    "                                                   update_every=1,\n",
    "                                                   chunksize=500,\n",
    "                                                   passes=20,\n",
    "                                                   alpha='auto')\n",
    "\n",
    "# ---------- Save model -----------\n",
    "\n",
    "lda_model_US.save(\"model_US.model\")\n",
    "\n",
    "# ---------- Evaluate model ----------\n",
    "perplex_US = lda_model_US.log_perplexity(corpus_US)\n",
    "print(perplex_US)\n",
    "\n",
    "coher_model_lda_US = CoherenceModel(model=lda_model_US, \n",
    "                                    texts=text_words_US_2, \n",
    "                                    dictionary=id2word_US,\n",
    "                                    corpus=corpus_US,\n",
    "                                    coherence='c_v')\n",
    "\n",
    "coherence_lda_US = coher_model_lda_US.get_coherence()\n",
    "print(coherence_lda_US)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### US: Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_US = pyLDAvis.gensim_models.prepare(lda_model_US,corpus_US,id2word_US,mds='mmds',R=20)\n",
    "vis_US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### US: Write topic results to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_US = lda_model_US.show_topics(formatted=False,num_topics=14,num_words=20)\n",
    "\n",
    "topic_words_US = []\n",
    "\n",
    "for i in range(lda_model_US.num_topics):\n",
    "    topic_words_US.extend([(i, )+ x for x in lda_model_US.show_topic(i, topn=20)])\n",
    "    \n",
    "df_out_US = pd.DataFrame(topic_words_US, columns=['Topic','Word','P'])\n",
    "df_out_US.to_csv('US_Topics.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country: GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GB:Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Clean text ----------\n",
    "lemma_text_GB, text_words_GB = clean_text(text_GB)\n",
    "\n",
    "print('Lemmatized: ',lemma_text_GB[0][0:100],'\\n')\n",
    "print('Tokenized: ',text_words_GB[0][0:20])\n",
    "\n",
    "# ---------- Create bigrams and trigrams ----------\n",
    "text_words_GB_2 =  tri_bigrams(text_words_GB,min_count=5,threshold=100)\n",
    "id2word_GB, corpus_GB = corpus_prep(text_words_GB_2)\n",
    "\n",
    "# ---------- TF-IDF and create corpus and dictionary ----------\n",
    "corpus_GB, id2words_GB = tf_idf(corpus_GB, id2word_GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GB: Find optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_GB, c_GB = opt_k(corpus_GB,id2word_GB,text_words_GB_2,\"GB_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(5,2.5))\n",
    "plt.tight_layout\n",
    "\n",
    "plt.plot(k_GB,c_GB)\n",
    "\n",
    "plt.title('Number of topics vs. coherence for GB')\n",
    "plt.xlabel('Number of topics')\n",
    "plt.ylabel('Coherence')\n",
    "plt.savefig('GB_Topics_K.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GB: Final LDA Model and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_GB = gensim.models.ldamulticore.LdaModel(corpus=corpus_GB,\n",
    "                                                   id2word=id2word_GB,\n",
    "                                                   num_topics=18,\n",
    "                                                   random_state=100,\n",
    "                                                   update_every=1,\n",
    "                                                   chunksize=500,\n",
    "                                                   passes=20,\n",
    "                                                   alpha='auto')\n",
    "\n",
    "# ---------- Save model -----------\n",
    "\n",
    "lda_model_GB.save(\"model_GB.model\")\n",
    "\n",
    "# ---------- Evaluate model ----------\n",
    "perplex_GB = lda_model_GB.log_perplexity(corpus_GB)\n",
    "print(perplex_GB)\n",
    "\n",
    "coher_model_lda_GB = CoherenceModel(model=lda_model_GB, \n",
    "                                    texts=text_words_GB_2, \n",
    "                                    dictionary=id2word_GB,\n",
    "                                    corpus=corpus_GB,\n",
    "                                    coherence='c_v')\n",
    "\n",
    "coherence_lda_GB = coher_model_lda_GB.get_coherence()\n",
    "print(coherence_lda_GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GB: Visualise topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_GB = pyLDAvis.gensim_models.prepare(lda_model_GB,corpus_GB,id2word_GB,mds='mmds',R=20)\n",
    "vis_GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GB: Write topic results to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_GB = lda_model_GB.show_topics(formatted=False,num_topics=18,num_words=20)\n",
    "\n",
    "topic_words_GB = []\n",
    "\n",
    "for i in range(lda_model_GB.num_topics):\n",
    "    topic_words_GB.extend([(i, )+ x for x in lda_model_GB.show_topic(i, topn=20)])\n",
    "    \n",
    "df_out_GB = pd.DataFrame(topic_words_GB, columns=['Topic','Word','P'])\n",
    "df_out_GB.to_csv('GB_Topics.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country: IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IN: Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Clean text ----------\n",
    "lemma_text_IN, text_words_IN = clean_text(text_IN)\n",
    "\n",
    "print('Lemmatized: ',lemma_text_IN[0][0:100],'\\n')\n",
    "print('Tokenized: ',text_words_IN[0][0:20])\n",
    "\n",
    "# ---------- Create bigrams and trigrams ----------\n",
    "text_words_IN_2 =  tri_bigrams(text_words_IN,min_count=5,threshold=100)\n",
    "id2word_IN, corpus_IN = corpus_prep(text_words_IN_2)\n",
    "\n",
    "# ---------- TF-IDF and create corpus and dictionary ----------\n",
    "corpus_IN, id2words_IN = tf_idf(corpus_IN, id2word_IN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IN: Find optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_IN, c_IN = opt_k(corpus_IN,id2word_IN,text_words_IN_2,\"IN_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(5,2.5))\n",
    "plt.tight_layout\n",
    "\n",
    "plt.plot(k_IN,c_IN)\n",
    "\n",
    "plt.title('Number of topics vs. coherence for IN')\n",
    "plt.xlabel('Number of topics')\n",
    "plt.ylabel('Coherence')\n",
    "plt.savefig('IN_Topics_K.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IN: Final model and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_IN = gensim.models.ldamulticore.LdaModel(corpus=corpus_IN,\n",
    "                                                   id2word=id2word_IN,\n",
    "                                                   num_topics=20,\n",
    "                                                   random_state=100,\n",
    "                                                   update_every=1,\n",
    "                                                   chunksize=500,\n",
    "                                                   passes=20,\n",
    "                                                   alpha='auto')\n",
    "\n",
    "# ---------- Save model -----------\n",
    "\n",
    "lda_model_IN.save(\"model_IN.model\")\n",
    "\n",
    "# ---------- Evaluate model ----------\n",
    "perplex_IN = lda_model_IN.log_perplexity(corpus_IN)\n",
    "print(perplex_IN)\n",
    "\n",
    "coher_model_lda_IN = CoherenceModel(model=lda_model_IN, \n",
    "                                    texts=text_words_IN_2, \n",
    "                                    dictionary=id2word_IN,\n",
    "                                    corpus=corpus_IN,\n",
    "                                    coherence='c_v')\n",
    "\n",
    "coherence_lda_IN = coher_model_lda_IN.get_coherence()\n",
    "print(coherence_lda_IN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_IN = pyLDAvis.gensim_models.prepare(lda_model_IN,corpus_IN,id2word_IN,mds='mmds',R=20)\n",
    "vis_IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write topic results to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_IN = lda_model_IN.show_topics(formatted=False,num_topics=20,num_words=20)\n",
    "\n",
    "topic_words_IN = []\n",
    "\n",
    "for i in range(lda_model_IN.num_topics):\n",
    "    topic_words_IN.extend([(i, )+ x for x in lda_model_IN.show_topic(i, topn=20)])\n",
    "    \n",
    "df_out_IN = pd.DataFrame(topic_words_IN, columns=['Topic','Word','P'])\n",
    "df_out_IN.to_csv('IN_Topics.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country: CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CA: Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Clean text ----------\n",
    "lemma_text_CA, text_words_CA = clean_text(text_CA)\n",
    "\n",
    "print('Lemmatized: ',lemma_text_CA[0][0:100],'\\n')\n",
    "print('Tokenized: ',text_words_CA[0][0:20])\n",
    "\n",
    "# ---------- Create bigrams and trigrams ----------\n",
    "text_words_CA_2 =  tri_bigrams(text_words_CA,min_count=5,threshold=100)\n",
    "id2word_CA, corpus_CA = corpus_prep(text_words_CA_2)\n",
    "\n",
    "# ---------- TF-IDF and create corpus and dictionary ----------\n",
    "corpus_CA, id2words_CA = tf_idf(corpus_CA, id2word_CA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CA: Find optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_CA, c_CA = opt_k(corpus_CA,id2word_CA,text_words_CA_2,\"CA_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(5,2.5))\n",
    "plt.tight_layout\n",
    "\n",
    "plt.plot(k_CA,c_CA)\n",
    "\n",
    "plt.title('Number of topics vs. coherence for CA')\n",
    "plt.xlabel('Number of topics')\n",
    "plt.ylabel('Coherence')\n",
    "plt.savefig('CA_Topics_K.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CA: Final LDA Model and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_CA = gensim.models.ldamulticore.LdaModel(corpus=corpus_CA,\n",
    "                                                   id2word=id2word_CA,\n",
    "                                                   num_topics=16,\n",
    "                                                   random_state=100,\n",
    "                                                   update_every=1,\n",
    "                                                   chunksize=500,\n",
    "                                                   passes=20,\n",
    "                                                   alpha='auto')\n",
    "\n",
    "# ---------- Save model -----------\n",
    "\n",
    "lda_model_CA.save(\"model_CA.model\")\n",
    "\n",
    "# ---------- Evaluate model ----------\n",
    "perplex_CA = lda_model_CA.log_perplexity(corpus_CA)\n",
    "print(perplex_CA)\n",
    "\n",
    "coher_model_lda_CA = CoherenceModel(model=lda_model_CA, \n",
    "                                    texts=text_words_CA_2, \n",
    "                                    dictionary=id2word_CA,\n",
    "                                    corpus=corpus_CA,\n",
    "                                    coherence='c_v')\n",
    "\n",
    "coherence_lda_CA = coher_model_lda_CA.get_coherence()\n",
    "print(coherence_lda_CA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_CA = pyLDAvis.gensim_models.prepare(lda_model_CA,corpus_CA,id2word_CA,mds='mmds',R=20)\n",
    "vis_CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write topic results to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_CA = lda_model_CA.show_topics(formatted=False,num_topics=16,num_words=20)\n",
    "\n",
    "topic_words_CA = []\n",
    "\n",
    "for i in range(lda_model_CA.num_topics):\n",
    "    topic_words_CA.extend([(i, )+ x for x in lda_model_CA.show_topic(i, topn=20)])\n",
    "    \n",
    "df_out_CA = pd.DataFrame(topic_words_CA, columns=['Topic','Word','P'])\n",
    "df_out_CA.to_csv('CA_Topics.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country: AU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AU: Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Clean text ----------\n",
    "lemma_text_AU, text_words_AU = clean_text(text_AU)\n",
    "\n",
    "print('Lemmatized: ',lemma_text_AU[0][0:100],'\\n')\n",
    "print('Tokenized: ',text_words_AU[0][0:20])\n",
    "\n",
    "# ---------- Create bigrams and trigrams ----------\n",
    "text_words_AU_2 =  tri_bigrams(text_words_AU,min_count=5,threshold=100)\n",
    "id2word_AU, corpus_AU = corpus_prep(text_words_AU_2)\n",
    "\n",
    "# ---------- TF-IDF and create corpus and dictionary ----------\n",
    "corpus_AU, id2words_AU = tf_idf(corpus_AU, id2word_AU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AU: Find optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_AU, c_AU = opt_k(corpus_AU,id2word_AU,text_words_AU_2,\"AU_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(5,2.5))\n",
    "plt.tight_layout\n",
    "\n",
    "plt.plot(k_AU,c_AU)\n",
    "\n",
    "plt.title('Number of topics vs. coherence for AU')\n",
    "plt.xlabel('Number of topics')\n",
    "plt.ylabel('Coherence')\n",
    "plt.savefig('AU_Topics_K.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_AU = gensim.models.ldamulticore.LdaModel(corpus=corpus_AU,\n",
    "                                                   id2word=id2word_AU,\n",
    "                                                   num_topics=22,\n",
    "                                                   random_state=100,\n",
    "                                                   update_every=1,\n",
    "                                                   chunksize=500,\n",
    "                                                   passes=20,\n",
    "                                                   alpha='auto')\n",
    "\n",
    "# ---------- Save model -----------\n",
    "\n",
    "lda_model_AU.save(\"model_AU.model\")\n",
    "\n",
    "# ---------- Evaluate model ----------\n",
    "perplex_AU = lda_model_AU.log_perplexity(corpus_AU)\n",
    "print(perplex_AU)\n",
    "\n",
    "coher_model_lda_AU = CoherenceModel(model=lda_model_AU, \n",
    "                                    texts=text_words_AU_2, \n",
    "                                    dictionary=id2word_AU,\n",
    "                                    corpus=corpus_AU,\n",
    "                                    coherence='c_v')\n",
    "\n",
    "coherence_lda_AU = coher_model_lda_AU.get_coherence()\n",
    "print(coherence_lda_AU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_AU = pyLDAvis.gensim_models.prepare(lda_model_AU,corpus_AU,id2word_AU,mds='mmds',R=20)\n",
    "vis_AU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write topic results to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_AU = lda_model_AU.show_topics(formatted=False,num_topics=22,num_words=20)\n",
    "\n",
    "topic_words_AU = []\n",
    "\n",
    "for i in range(lda_model_AU.num_topics):\n",
    "    topic_words_AU.extend([(i, )+ x for x in lda_model_AU.show_topic(i, topn=20)])\n",
    "    \n",
    "df_out_AU = pd.DataFrame(topic_words_AU, columns=['Topic','Word','P'])\n",
    "df_out_AU.to_csv('AU_Topics.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country: ZA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ZA: Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Clean text ----------\n",
    "lemma_text_ZA, text_words_ZA = clean_text(text_ZA)\n",
    "\n",
    "print('Lemmatized: ',lemma_text_ZA[0][0:100],'\\n')\n",
    "print('Tokenized: ',text_words_ZA[0][0:20])\n",
    "\n",
    "# ---------- Create bigrams and trigrams ----------\n",
    "text_words_ZA_2 =  tri_bigrams(text_words_ZA,min_count=5,threshold=100)\n",
    "id2word_ZA, corpus_ZA = corpus_prep(text_words_ZA_2)\n",
    "\n",
    "# ---------- TF-IDF and create corpus and dictionary ----------\n",
    "corpus_ZA, id2words_ZA = tf_idf(corpus_ZA, id2word_ZA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ZA: Find optimal number of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ZA, c_ZA = opt_k(corpus_ZA,id2word_ZA,text_words_ZA_2,\"ZA_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(5,2.5))\n",
    "plt.tight_layout\n",
    "\n",
    "plt.plot(k_ZA,c_ZA)\n",
    "\n",
    "plt.title('Number of topics vs. coherence for ZA')\n",
    "plt.xlabel('Number of topics')\n",
    "plt.ylabel('Coherence')\n",
    "plt.savefig('ZA_Topics_K.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_ZA = gensim.models.ldamulticore.LdaModel(corpus=corpus_ZA,\n",
    "                                                   id2word=id2word_ZA,\n",
    "                                                   num_topics=22,\n",
    "                                                   random_state=100,\n",
    "                                                   update_every=1,\n",
    "                                                   chunksize=500,\n",
    "                                                   passes=20,\n",
    "                                                   alpha='auto')\n",
    "\n",
    "# ---------- Save model -----------\n",
    "\n",
    "lda_model_ZA.save(\"model_ZA.model\")\n",
    "\n",
    "# ---------- Evaluate model ----------\n",
    "perplex_ZA = lda_model_ZA.log_perplexity(corpus_ZA)\n",
    "print(perplex_ZA)\n",
    "\n",
    "coher_model_lda_ZA = CoherenceModel(model=lda_model_ZA, \n",
    "                                    texts=text_words_ZA_2, \n",
    "                                    dictionary=id2word_ZA,\n",
    "                                    corpus=corpus_ZA,\n",
    "                                    coherence='c_v')\n",
    "\n",
    "coherence_lda_ZA = coher_model_lda_ZA.get_coherence()\n",
    "print(coherence_lda_ZA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_ZA = pyLDAvis.gensim_models.prepare(lda_model_ZA,corpus_ZA,id2word_ZA,mds='mmds',R=20)\n",
    "vis_ZA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ZA: Write topic results to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_ZA = lda_model_ZA.show_topics(formatted=False,num_topics=22,num_words=20)\n",
    "\n",
    "topic_words_ZA = []\n",
    "\n",
    "for i in range(lda_model_ZA.num_topics):\n",
    "    topic_words_ZA.extend([(i, )+ x for x in lda_model_ZA.show_topic(i, topn=20)])\n",
    "    \n",
    "df_out_ZA = pd.DataFrame(topic_words_ZA, columns=['Topic','Word','P'])\n",
    "df_out_ZA.to_csv('ZA_Topics.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
